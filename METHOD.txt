Atomic Tasks – Development Method, Decisions, and AI Usage
=========================================================

This document explains **how** the technical assessment was tackled:

- The architectural approach and how it maps to the brief.
- Key design decisions and any changes made along the way.
- How AI tools (Cursor and ChatGPT‑5) were used.
- The high‑level TODO / implementation plan that guided development.

For instructions on how to **run** and **test** the application, see `README.md`.


1. Architectural approach
-------------------------

### 1.1 Overall style – modular monolith

The backend is implemented as a **modular monolith**:

- A single deployable .NET 9 Web API.
- Clear internal separation into `Domain`, `Application`, `Infrastructure`, and `Api` layers.
- A separate React + TypeScript client in `src/client`.

This keeps local development and deployment simple (one backend, one frontend), while still making it easy to explain how the system could be split into microservices later (for example, by extracting `Tasks` into its own service with its own database).

### 1.2 Backend layers

- **Domain layer (`AtomicTasks.Domain`)**
  - Contains the `Task` entity and core rules.
  - Final shape aligned strictly to the assessment spec:
    - `int Id`
    - `bool IsCompleted` (default `false`)
    - `string Title` (required, max length **100**)
    - `string? Description`
    - `DateTime? DueDate`
    - `DateTime CreatedAt`
    - `DateTime UpdatedAt`

- **Application layer (`AtomicTasks.Application`)**
  - Contains the use‑cases and orchestration logic.
  - Exposes interfaces and DTOs to keep the Web API and persistence concerns decoupled:
    - `ITaskService` – service interface used by the API layer.
    - `ITaskRepository` – abstraction over persistence.
    - DTOs and request models: `TaskDto`, `CreateTaskRequest`, `UpdateTaskRequest`.
  - Business logic includes:
    - Trimming and validating titles (non‑empty, <= 100 chars).
    - Mapping between domain entities and DTOs.
    - Passing filter/sort/pagination parameters down to the repository.

- **Infrastructure layer (`AtomicTasks.Infrastructure`)**
  - Provides an `AtomicTasksDbContext` configured for **SQLite**.
  - Implements `ITaskRepository` via `EfTaskRepository`, including:
    - Querying by completion state.
    - Optional due‑date range.
    - Optional search term across title/description.
    - Sorting (created date, due date, title) and simple pagination.
  - Uses `Database.EnsureCreated()` at startup to simplify local setup.

- **API layer (`AtomicTasks.Api`)**
  - ASP.NET Core minimal API hosting the HTTP endpoints under `/api/tasks`.
  - Depends on the `ITaskService` abstraction rather than talking directly to EF Core.
  - Configures DI, DbContext, CORS, and JSON options.
  - Implements endpoints:
    - `GET /api/tasks` with optional filters (`isCompleted`, `dueFrom`, `dueTo`), sorting (`sortBy`, `sortDirection`), and pagination (`page`, `pageSize`).
    - `GET /api/tasks/{id}`
    - `POST /api/tasks`
    - `PUT /api/tasks/{id}`
    - `DELETE /api/tasks/{id}`
  - Returns appropriate HTTP status codes for validation failures and not‑found cases.


2. Frontend approach
--------------------

### 2.1 Stack and structure

- **React 18 + TypeScript**, scaffolded via Vite in `src/client`.
- A single main entry point at `src/client/src/main.ts`.
- Styling in `src/client/src/style.css`, kept lightweight but clean and modern.

### 2.2 Routing and views

The brief called for distinct views and the ability to navigate between them. To keep dependencies minimal while satisfying the requirement, a simple **custom router** was implemented using the browser history API:

- Supported routes:
  - `/tasks` – main task list.
  - `/tasks/new` – add new task.
  - `/tasks/{id}` – edit existing task.
- The router is a small helper (`parseRoute`) that inspects `window.location.pathname` and drives a `Route` discriminated union in React state.

Views are rendered conditionally based on the current `route`:

- **List view**:
  - Table of tasks with columns: title, status, due date, created date, and actions.
  - Buttons for toggle completion, edit, and delete.
  - Filter controls for completion state and due date range.
  - Sorting controls (by created date, due date, and title; ascending/descending).
  - Pagination controls (Previous / Next) backed by the API’s pagination support.
- **Add / edit view**:
  - Single form with:
    - Title (required, validated, max length 100).
    - Due date (optional).
    - Description (optional, textarea).
  - Shows inline validation errors (e.g. “Title is required”).
  - Reuses the same component for both “add” and “edit” flows, with state initialised from the selected task when editing.

### 2.3 API integration

The frontend talks to the backend via the REST API using `fetch`:

- Base URL is configured via `VITE_API_BASE_URL` (with `/api` as a default fallback).
- All calls use JSON and align with the DTOs exposed by the backend.
- The list view builds up a query string from the current filters, sorting, and pagination state and calls `GET /tasks` accordingly.


3. Alignment with the assessment spec
-------------------------------------

The brief specified a concrete data model and behaviours. Key alignment points:

- **Data model**:
  - `Task` uses `int Id`, `bool IsCompleted`, `string Title` (max 100), optional `Description`, optional `DueDate`.
  - Both backend and frontend use the same shape; type mismatches from earlier iterations (e.g. GUID IDs, enums for status/priority) were removed and corrected.

- **API surface and filtering/sorting**:
  - CRUD endpoints are implemented as required.
  - `GET /api/tasks` supports server‑side filtering (completion, due date range), search, sorting, and pagination, which the UI surfaces via controls.

- **Service layer and tests**:
  - Explicit `TaskService` and `ITaskService` interface in the Application layer.
  - API endpoints depend on the service, not directly on repositories.
  - Unit tests with Moq validate key service behaviours.

- **Frontend UX**:
  - Separate views for listing, adding, and editing tasks.
  - Completion toggling and deletion supported with confirmations and error handling.
  - Clean, responsive layout with clear labels, state pills (Pending / Completed), and helpful error messages.

Any deviations identified during development (such as initial enum‑based status/priority fields or GUID IDs) were treated as bugs relative to the brief and corrected as a priority.


4. Testing strategy
-------------------

### 4.1 Backend tests

Tests live under `tests/server/AtomicTasks.Tests` and use **xUnit**:

- **Repository tests**:
  - Exercise `EfTaskRepository` with the in‑memory EF Core provider.
  - Verify that tasks can be added and queried back correctly.
- **Service tests**:
  - Use **Moq** to mock `ITaskRepository`.
  - Verify that `TaskService` correctly enforces title rules, default values, and maps between DTOs and entities.

These tests demonstrate the layering (Application vs Infrastructure) and validate behaviour without needing to spin up the full API.

### 4.2 Frontend unit tests

Frontend unit tests use **Vitest** and **React Testing Library**:

- Located in `src/client/src/App.test.tsx`.
- Cover:
  - Rendering of the main “Atomic Tasks” header.
  - Validation behaviour when submitting a task without a title.
  - Rendering of tasks returned from a mocked API response (including Pending status).

The tests mock `fetch` to keep them fast and deterministic.

### 4.3 Frontend end-to-end tests

End‑to‑end tests use **Playwright** and live under `src/client/tests/e2e`:

- Configured via `src/client/playwright.config.ts`.
- Key flows covered:
  - Creating a new task via the UI and verifying it appears in the list.
  - Toggling completion for a specific task (creating it first if necessary).

These tests talk to the real API and frontend dev server, providing confidence that the main user journeys work as expected.


5. Use of AI tools (Cursor + ChatGPT‑5)
--------------------------------------

The assessment explicitly allowed (and asked about) the use of AI tools. This section documents how they were used.

- **Planning and breakdown**:
  - AI was used to read and summarise the assessment PDFs and derive a clear, structured TODO list.
  - The TODO list was refined iteratively as gaps were discovered (for example, the need for an explicit service layer and frontend E2E tests).

- **Architecture discussions**:
  - Several options were discussed, including microservices vs modular monolith.
  - The final choice of a modular monolith with clear boundaries was taken to balance simplicity and realism.

- **Code scaffolding and refactoring**:
  - Boilerplate code was sometimes generated with AI assistance (e.g. DTOs, mapping functions, initial EF Core setup).
  - Refactorings were suggested when the implementation drifted from the spec (e.g. removing enums in favour of `IsCompleted`, switching ID types to `int`, enforcing title length).

- **Debugging and error resolution**:
  - AI was used to diagnose build and runtime issues, including:
    - EF Core version mismatches with .NET 9.
    - Windows “Access is denied” errors when launching the API (resolved via `<UseAppHost>false>`).
    - JSON serialisation issues and TypeScript compile errors during model changes.

- **Documentation and polish**:
  - Portions of this `METHOD.txt` and `README.md` were drafted and then edited with AI help.
  - AI was treated as a collaborator for wording and structure, not as an authority on requirements.

All significant design decisions, code changes, and final verification were performed and signed off manually. AI output was always treated as a suggestion to be checked against the written brief and actual behaviour.


6. High-level implementation plan / TODO
----------------------------------------

This plan was used to drive the work and is preserved here to show how the assessment was approached.

1. **Clarify requirements**
   - Extract assessment requirements and constraints (features, tech constraints, AI usage rules, submission format).
2. **Choose stack & layout**
   - Decide on React + TypeScript frontend, .NET 9 API backend, SQLite database, and the project structure above.
3. **Design architecture**
   - Finalise the modular monolith architecture with clear `Domain`, `Application`, `Infrastructure`, and `Api` boundaries.
   - Explain how it could evolve into microservices if needed.
4. **Data model & API surface**
   - Define the `Task` domain model and REST API endpoints.
   - Later, refactor to ensure perfect alignment with the assessment spec (int IDs, `IsCompleted` boolean, title max 100, optional description/due date).
5. **Backend core implementation**
   - Implement task CRUD, business rules, and persistence with SQLite.
   - Add basic validation and error handling for invalid requests.
6. **Frontend core implementation**
   - Build the React + TypeScript UI:
     - Task list.
     - Create/edit forms.
     - Completion toggle and delete.
     - Loading/error states.
7. **Routing and enhanced list behaviour**
   - Introduce client‑side routing for separate list/add/edit views.
   - Implement list filters, sorting, and pagination wired to matching API query parameters.
8. **Testing**
   - Add backend unit and integration tests (mappings, repository, service with mocks).
   - Add frontend unit tests for key flows.
   - Add Playwright end‑to‑end tests for core user journeys.
9. **Azure notes and submission polish**
   - Outline a simple Azure deployment path (App Service + managed database).
   - Finalise `README.md` and this `METHOD.txt` so reviewers can quickly run, test, and understand the solution.



